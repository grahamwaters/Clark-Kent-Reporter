{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5138b818",
   "metadata": {},
   "source": [
    "# Lorebook Generator Engine for use with NovelAI\n",
    "**A project by Graham Waters, prepared 2022-11-12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309b2d5",
   "metadata": {},
   "source": [
    "How to Contribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ccd6b",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7001b33f",
   "metadata": {},
   "source": [
    "\n",
    " This repo is designed to help all of us as authors using NovelAI. It pulls from Wikipedia articles to automatically generate lorebooks for real places or years and pretty much anything you could find on Wikipedia using python's wikipedia library. The repo contains two different versions: a basic one that generates based on a CSV file, 'characters.csv' and a more advanced version that implements multiple keywords for a more tailored search.    <a name=\"readme-top\"></a>               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed0060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1730d52d",
   "metadata": {},
   "source": [
    "## About The Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2e7b9",
   "metadata": {},
   "source": [
    "\n",
    " This project is designed to augment the fantastic work being done by the NovelAI team to make AI writing a reality. In its simplest form, this tool provides the extra thoughts that you want to remind your AI of when it is writing. In its more advanced form, it can be used to generate a lorebook for a specific year or place, which can be used to help the AI understand the world it is writing about.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2b67929",
   "metadata": {},
   "source": [
    "### Basic Comments and Feedback (so far)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d663b2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Section Text Not Found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e717fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb113f5",
   "metadata": {},
   "source": [
    "## How to use this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27842060",
   "metadata": {},
   "source": [
    "\n",
    " To use this lorebook generator, follow these steps:  - If you are going to contribute or add things to the repository, fork it before you start. - To start, you need to clone the repo to your local machine. You can do this by running the following command in your terminal:  Note: you will need to replace the url with your forked repos url. If you are not going to contribute, you can use the original url.  ```bash git clone https://github.com/grahamwaters/lorebook_generator_for_novelai ```  Then make sure you navigate into the directory:  ```bash cd lorebook_generator_for_novelai ```  - Next, you need to install the dependencies. You can do this by running the following command:  ```bash pip install -r requirements.txt ```  So, what exactly does this do? Well, it installs all of the dependencies that are required to run the code. You can see the dependencies in the requirements.txt file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545767f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db55bea6",
   "metadata": {},
   "source": [
    "## How does the basic version work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11440b2",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65df0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccdb8c92",
   "metadata": {},
   "source": [
    "### Figure A. Basic version (example of keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113856ab",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Section Text Not Found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57819205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3e9738c",
   "metadata": {},
   "source": [
    "### Mode 1. Basic Mode - Using a CSV file to generate lorebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfaf8a7",
   "metadata": {},
   "source": [
    "\n",
    "- Once you have it cloned, populate the `characters.csv` file with your chosen keywords. (You can use the example file as a template.) - Then run the python script [scripts/03_lorebook_from_wiki_withpulls.py](scripts/03_lorebook_from_wiki_withpulls.py), and it will generate a lorebook for you. This lorebook will be named `lorebook_generated.lorebook` and will be saved in the `supporting_files` folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08a235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908edec0",
   "metadata": {},
   "source": [
    "### Mode 2. Subtopics -> to keywords -> to lorebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ee217",
   "metadata": {},
   "source": [
    "\n",
    "If you're feeling adventurous but not super productive, you can provide one topic (wikipedia page) to the [mode_2](./scripts/04_get_relevant_subtopics.py) script and it will generate a list of keywords that are relevant to that topic. Then it will generate a lorebook for you based on those keywords. This is a good way to get a quick lorebook for a topic that you don't know much about. It does currently have limitations in that it will provide WAY more information than you may need for a lorebook. So you may need to do some editing to get it to a place where you're happy with it.    ![](images/greatpyramid.png)  The code pulls the wiki page for each character or topic/place in the provided characters file. In the case of the pyramid of Giza, it will scan the text of the article for the significant NNS and NNPS (nouns) and then generate a lorebook with the article's text as the meat of the entry, and each of the unique words will be added in as keywords for NovelAI (which will allow the AI to trigger this entry). The script will also generate a list of the nouns it found in the article, which you can use to add to the characters.csv file if you are interested in building out a more robust contextually dense lorebook.  - Once you have a lorebook created, you can upload the lorebook to NovelAI and use it to add background detail to your stories and characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fd21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa058a46",
   "metadata": {},
   "source": [
    "# How to Contribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38799e3c",
   "metadata": {},
   "source": [
    "\n",
    " Have an idea? Make a pull request! Don't be shy!  We are seeking contributors that are skilled at project organization and formatting. If you are interested in helping out, please contact me on Discord: `@its_graham#7425` Also, feel free to open issues, pull requests, and make suggestions for this project here on GitHub as well. Working together, we could add some more features to the program, like web scraping historical documents or corpora from Project Gutenberg! That would be really informative. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6405c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "342258dd",
   "metadata": {},
   "source": [
    "## Included Files -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a534a",
   "metadata": {},
   "source": [
    "\n",
    "- [year_specific_lorebook.py](scripts/01_lorebook_from_year.py) This script generates a lorebook based on a year. It pulls from Wikipedia articles and generates a lorebook based on the year you input. It also generates a list of characters that are mentioned in the article. This is a good way to get a feel for the program and how it works.  - [Lorebook From Articles](scripts/02_lorebook_from_downloaded_wiki_articles.py) This script generates a lorebook based on a list of keywords. It pulls from Wikipedia articles and generates a lorebook based on the keywords you input. It also generates a list of characters that are mentioned in the article. This is a good way to get a feel for the program and how it works.  - [characters.csv](characters.csv)  This is a CSV file that contains a list of characters that are mentioned in the lorebook. It is generated by the scripts above and will be originally populated by the author to fit their story.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1047b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3679f7f1",
   "metadata": {},
   "source": [
    "# Areas Currently in Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a71425",
   "metadata": {},
   "source": [
    "\n",
    "- [ ] Working through the notebooks in `notebooks/` to make sure they are up to date with the scripts in `scripts/` and that they are needed. - [ ] Improving the quality of the generated lorebooks in the following areas:   - [ ] Parsed Text Extraction Valence Optimization - Currently the text extraction is not perfect. We need to improve the valence of the text extraction to make sure that the text is relevant to the topic being queried. This is a big one.   - [ ] Integrating sklearn or potentially other libraries to improve the quality of the generated text. (i.e., PyTorch, TensorFlow, etc.)   - [ ] Identification of instances in the text where the following pattern exists:     - [ ] `character one` and `character two` are both mentioned within some distance `d` of each other. This is an interesting method of identifying characters that are related to each other. Proximity could be useful in determining how these topics or characters should be considered.   - The code is currently adding a huge number of keys to the lorebook. This is potentially causing problems on the server side of NovelAI. I will reduce the key count to less than fifty and see if that helps.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eede00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63451bec",
   "metadata": {},
   "source": [
    "## Future Development Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953687ad",
   "metadata": {},
   "source": [
    "\n",
    "- [place_specific_lorebook.py](scripts/02_lorebook_from_place.py) - This script will be used to generate lorebooks from a specific place. We will do this by using the Wikipedia library to search for a place and then using the article text as the lorebook entry.  I find [jidbc's work with gutenberg](https://github.com/jldbc/gutenberg.git) as a recommender system to be particularly fascinating. This will make a great addition to the project. I will be working on integrating this into the project in the near future. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079c4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d20f6290",
   "metadata": {},
   "source": [
    "# Notes on the Git Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939ae53",
   "metadata": {},
   "source": [
    "\n",
    "Make sure to include the following in your `.gitignore` when you fork this repo: - /wikipedia_pages - /master_pages - .lorebook  This will ensure that your literary work is kept confidential and that it is separated from the code improvements you discover along the way.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef9754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27eda56f",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75060b",
   "metadata": {},
   "source": [
    "\n",
    " - [@grahamwaters](https://www.github.com/grahamwaters)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce0f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cb0d0e6",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913adf8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Section Text Not Found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407de283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
